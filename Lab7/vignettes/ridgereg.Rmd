---
title: "Ridge Regression"
author: "Balaji Ramkumar and Amish Satish"
date: "13/10/2017"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This is a function for the usage of Ridge Regression. It is a part of the line reg package that was created earlier.The output value is also compared with the output generated by **lm.ridge()** function that belongs to MASS package.

We take a data called as **BostonHousing Data** and test it with all the three models to check for the performance.

#Installing BostonHousing Data
```{r}
library(mlbench)
library(caret)
library(statPack)
```

#Loading the data and creating a training set
```{r}
data("BostonHousing") 
boston_data <- BostonHousing 
indexes = createDataPartition(boston_data$medv, p = .45, list = FALSE, times = 1)
training_set<- boston_data[indexes,] 
testing_set<- boston_data[-indexes,]  
```

#Training the data using lm and leapforward
```{r}
set.seed(-312312L)
ridgereg_lm <- train(rm ~ . , data = training, method = "lm")
print(ridgereg_lm)

ridgereg_leap <- train(rm ~ ., data = training, method = "leapForward")
print(ridgereg_leap)
```

#Setting up Ridge
```{r}
ridge <- list(type="Regression", 
              library="statPack",
              loop=NULL,
              prob=NULL)
ridge$parameters <- data.frame(parameter="lambda",
                               class="numeric",
                               label="lambda")
ridge$grid <- function(y,x, len=NULL, search="grid"){
  data.frame(lambda=c(0.2,0.6,1,2))
}
ridge$fit <- function (x, y, wts, param, lev, last, classProbs, ...) {
  dat <- if (is.data.frame(x)) 
    x
  else as.data.frame(x)
  dat$.outcome <- y
  out <- ridgereg$new(.outcome ~ ., data = dat, lambda=param$lambda, ...)
  out
}
ridge$predict <- function (modelFit, new, submodels = NULL) {
  if (!is.data.frame(new)) 
    new <- as.data.frame(new)
  new[,apply(new, MARGIN=2, sd)!=0] <- scale(new[,apply(new, MARGIN=2, sd)!=0])
  modelFit$predict(new)
}
```

#Using 10-fold cross validation
```{r}
cont <- trainControl(method = "repeatedcv",
                        number=10,
                        repeats = 10)


 result <- train(crim ~ ., data = training,method = ridgemodel,preProc = c("scale","center"),
       tuneLength = 10,trControl = cont)
```

#Result

The RMSE values for 3 models gives the result that ridge model is the best out of the three.
